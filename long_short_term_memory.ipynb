{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory (LSTM)\n",
    "\n",
    "## LSTM is a type of RNN that can remember past values over long periods of time. It is useful for predicting stock prices that have long-term dependencies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('commbank.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'Date' column as index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Scale the data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = scaled_data[:int(0.8 * len(df)), :]\n",
    "test_data = scaled_data[int(0.8 * len(df)):, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create data sequences for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create data sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        x.append(data[i-seq_length:i, :])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# Create sequences for training and testing\n",
    "seq_length = 60\n",
    "train_x, train_y = create_sequences(train_data, seq_length)\n",
    "test_x, test_y = create_sequences(test_data, seq_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Build the LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(units=50, return_sequences=True, input_shape=(train_x.shape[1], train_x.shape[2])),\n",
    "    LSTM(units=50, return_sequences=True),\n",
    "    LSTM(units=50),\n",
    "    Dense(units=1)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_x, train_y, epochs=50, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted closing prices\n",
    "predictions = model.predict(test_x)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Get the actual closing prices\n",
    "actuals = scaler.inverse_transform(test_y.reshape(-1, 1))\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "r2 = r2_score(actuals, predictions)\n",
    "\n",
    "print('MSE: ', mse)\n",
    "print('RMSE: ', rmse)\n",
    "print('MAE: ', mae)\n",
    "print('R2: ', r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted closing prices\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(actuals, color='blue', label='Actual')\n",
    "plt.plot(predictions, color='red', label='Predicted')\n",
    "plt.title('Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(history.history['loss'], color='blue', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
